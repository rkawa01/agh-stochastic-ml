{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Critical Look at Cuckoo Search\n",
    "\n",
    "This lab explores the common issue of seemingly new optimization algorithms that may not offer genuinely novel ideas. We'll first examine the original Cuckoo Search paper and then critically analyze it using the paper \"An analysis of why cuckoo search does not bring any novel ideas to optimization.\" This exercise builds on our previous discussions of evolutionary algorithms like Differential Evolution and the pitfalls of poor research in fields like Neuroevolution, focusing here on the problem of redundant concepts in optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from typing import Callable\n",
    "from dataclasses import dataclass\n",
    "from math import gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Problems\n",
    "\n",
    "This cell defines three common benchmark functions, Sphere, Rosenbrock, and Rastrigin, used to test optimization algorithms. We also used these functions earlier to evaluate Adam, Momentum, and CMA-ES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere(x: np.ndarray) -> float:\n",
    "    return float(np.sum(x**2))\n",
    "\n",
    "\n",
    "def rosenbrock(x: np.ndarray) -> float:\n",
    "    return float(np.sum(100.0 * (x[1:] - x[:-1] ** 2.0) ** 2.0 + (1.0 - x[:-1]) ** 2.0))\n",
    "\n",
    "\n",
    "def rastrigin(x: np.ndarray) -> float:\n",
    "    A: float = 10.0\n",
    "    return float(A * len(x) + np.sum(x**2 - A * np.cos(2 * np.pi * x)))\n",
    "\n",
    "BOUNDS = [(-5, 5), (-5, 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Search Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_cs(\n",
    "    func: Callable[[np.ndarray], float],\n",
    "    history: list[np.ndarray],\n",
    "    bounds: list[tuple[float, float]] = BOUNDS,\n",
    "    frames: int | None = None,\n",
    "    filename: str = \"cs_animation.gif\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Creates and saves a GIF showing how the CS population moves over generations.\n",
    "    \"\"\"\n",
    "    if frames is None:\n",
    "        frames = len(history)\n",
    "\n",
    "    assert len(bounds) == 2, \"This function only supports 2D visualization (expected 2 bounds).\"\n",
    "    x_bounds = (bounds[0][0], bounds[0][1])\n",
    "    y_bounds = (bounds[1][0], bounds[1][1])\n",
    "\n",
    "    x = np.linspace(x_bounds[0], x_bounds[1], 200)\n",
    "    y = np.linspace(y_bounds[0], y_bounds[1], 200)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    coords = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    Z = np.array([func(pt) for pt in coords]).reshape(X.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    contour = ax.contourf(X, Y, Z, levels=20, cmap=\"viridis\")\n",
    "    fig.colorbar(contour, ax=ax)\n",
    "    \n",
    "    def init():\n",
    "        scatter = ax.scatter([], [], s=20, color=\"red\")\n",
    "        return (scatter,)\n",
    "    \n",
    "    def update(i: int):\n",
    "        ax.set_title(f\"Generation {i}\")\n",
    "        pop = history[i]\n",
    "        scatter = ax.scatter(pop[:, 0], pop[:, 1], s=20, color=\"red\")\n",
    "        return (scatter,)\n",
    "    \n",
    "    ax.set_xlim(x_bounds[0], x_bounds[1])\n",
    "    ax.set_ylim(y_bounds[0], y_bounds[1])\n",
    "    \n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update, init_func=init, frames=frames, interval=200, blit=True\n",
    "    )\n",
    "    \n",
    "    writer = animation.PillowWriter(fps=5)\n",
    "    anim.save(filename, writer=writer)\n",
    "    plt.close(fig)\n",
    "    print(f\"Animation saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Read [Cuckoo Search via Levy Flights](https://arxiv.org/pdf/1003.1594) with particular attention to Sections 2, 3, and 4. The primary focus for this exercise is Figure 1, which outlines the core pseudocode of the algorithm.\n",
    "\n",
    "Your task is to implement the Cuckoo Search algorithm, using Figure 1 as your main reference. As the pseudocode is relatively high-level and lacks \n",
    "implementation details, you are encouraged to adopt a straightforward approach in your implementation.\n",
    "\n",
    "**Action Item:** Document any ambiguities or unclear aspects you encounter in the algorithm description or pseudocode.\n",
    "\n",
    "> Note: If you find the implementation too challenging or feel stuck, you may proceed directly to Exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CSResult:\n",
    "    best_vector: np.ndarray\n",
    "    best_value: float\n",
    "    history: list[np.ndarray]  # History of populations for animation\n",
    "\n",
    "\n",
    "class LevyFlight:\n",
    "    def __init__(self, beta: float = 1.5):\n",
    "        self.beta = beta\n",
    "\n",
    "    def __call__(self, size: int) -> np.ndarray:\n",
    "        sigma_u = (\n",
    "            gamma(1 + self.beta)\n",
    "            * np.sin(np.pi * self.beta / 2)\n",
    "            / (gamma((1 + self.beta) / 2) * self.beta * 2 ** ((self.beta - 1) / 2))\n",
    "        ) ** (1 / self.beta)\n",
    "        sigma_v = 1\n",
    "        u = np.random.normal(0, sigma_u, size)\n",
    "        v = np.random.normal(0, sigma_v, size)\n",
    "        step = u / np.abs(v) ** (1 / self.beta)\n",
    "        return step\n",
    "\n",
    "\n",
    "def cuckoo_search(\n",
    "    func: Callable[[np.ndarray], float],\n",
    "    bounds: list[tuple[float, float]] = BOUNDS,\n",
    "    pop_size: int = 50,\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.5,\n",
    "    p: float = 0.25,\n",
    "    max_gen: int = 100,\n",
    ") -> CSResult:\n",
    "    \"\"\"\n",
    "    Implements the Cuckoo Search algorithm for global optimization.\n",
    "\n",
    "    Parameters:\n",
    "        func: Objective function to minimize. Takes a numpy array and returns a float.\n",
    "        bounds: list of (min, max) pairs for each dimension.\n",
    "        pop_size: Number of individuals in the population.\n",
    "        alpha: Step-size scaling factor controlling the overall scale of the Lévy flights.\n",
    "        beta: Exponent parameter for the Lévy distribution (typically in (1, 3]) that\n",
    "            influences the heavy-tailed step-length distribution.\n",
    "        p: Probability (in [0, 1]) that a host bird discovers an alien egg and abandons\n",
    "            the corresponding nest—i.e., fraction of worse nests to be replaced each generation.\n",
    "        max_gen: Maximum number of generations to evolve.\n",
    "    \"\"\"\n",
    "    dimensions = len(bounds)\n",
    "    lower_bounds = np.array([b[0] for b in bounds])\n",
    "    upper_bounds = np.array([b[1] for b in bounds])\n",
    "\n",
    "    # Initialize the population\n",
    "    population = np.random.uniform(\n",
    "        low=lower_bounds, high=upper_bounds, size=(pop_size, dimensions)\n",
    "    )\n",
    "    fitness = np.array([func(ind) for ind in population])\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best_vector = population[best_idx].copy()\n",
    "    best_value = fitness[best_idx]\n",
    "    history = [population.copy()]\n",
    "\n",
    "    levy = LevyFlight(beta=beta)\n",
    "\n",
    "    for generation in range(max_gen):\n",
    "        # Generate new solutions (cuckoos) via Lévy flights\n",
    "        for i in range(pop_size):\n",
    "            step = alpha * levy(dimensions)\n",
    "            new_sol = population[i] + step \n",
    "            # Apply bounds\n",
    "            new_sol = np.clip(new_sol, lower_bounds, upper_bounds)\n",
    "            new_fit = func(new_sol)\n",
    "            # Choose a random nest index different from i\n",
    "            j = i\n",
    "            while j == i:\n",
    "                j = np.random.randint(pop_size)\n",
    "            if new_fit < fitness[j]:\n",
    "                population[j] = new_sol\n",
    "                fitness[j] = new_fit\n",
    "                if new_fit < best_value:\n",
    "                    best_value = new_fit\n",
    "                    best_vector = new_sol.copy()\n",
    "\n",
    "        # Abandon a fraction p of the worst nests and replace them\n",
    "        num_abandon = int(p * pop_size)\n",
    "        if num_abandon > 0:\n",
    "            worst_idx = np.argsort(fitness)[-num_abandon:]\n",
    "            for idx in worst_idx:\n",
    "                new_nest = np.random.uniform(low=lower_bounds, high=upper_bounds, size=dimensions)\n",
    "                population[idx] = new_nest\n",
    "                fitness[idx] = func(new_nest)\n",
    "                if fitness[idx] < best_value:\n",
    "                    best_value = fitness[idx]\n",
    "                    best_vector = new_nest.copy()\n",
    "\n",
    "        history.append(population.copy())\n",
    "\n",
    "    return CSResult(best_vector=best_vector, best_value=best_value, history=history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test implemented CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cuckoo_search(sphere, bounds=BOUNDS, pop_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "\n",
    "Run CS on all three problems: Sphere, Rosenbrock and Rastrigin. For each problem:\n",
    "- Visualize the population dynamics over time to illustrate how the search space is explored and exploited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CS on Sphere function...\n",
      "Animation saved to cs_sphere.gif\n",
      "Running CS on Rosenbrock function...\n",
      "Animation saved to cs_rosenbrock.gif\n",
      "Running CS on Rastrigin function...\n",
      "Animation saved to cs_rastrigin.gif\n"
     ]
    }
   ],
   "source": [
    "# Run Cuckoo Search on all three benchmark problems and visualize the population dynamics\n",
    "\n",
    "problems = [\n",
    "    (\"Sphere\", sphere),\n",
    "    (\"Rosenbrock\", rosenbrock),\n",
    "    (\"Rastrigin\", rastrigin),\n",
    "]\n",
    "\n",
    "for name, func in problems:\n",
    "    print(f\"Running CS on {name} function...\")\n",
    "    result = cuckoo_search(func, bounds=BOUNDS, pop_size=50)\n",
    "    animate_cs(func, result.history, bounds=BOUNDS, filename=f\"cs_{name.lower()}.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Read [An analysis of why cuckoo search does not bring any novel ideas to optimization](https://www.sciencedirect.com/science/article/pii/S0305054822000442). Focus particularly on Sections 2 and 3. Section 2.3 provides a detailed description of the implemented Cuckoo Search algorithm. Carefully analyze and compare it with your own, highlighting any differences in assumptions, parameter settings, or algorithmic structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of My Cuckoo Search Implementation vs. the Paper\n",
    "\n",
    "**Selection Step:**\n",
    "In my code, when a new solution (generated by a Lévy flight) is created, I compare it to a randomly chosen nest from the population. If the new solution is better, it replaces the random nest. This follows the pseudocode from Yang and Deb’s original paper.\n",
    "In contrast, the analysis paper describes a different approach: each new solution is compared only to its own previous version (the \"parent\"), and only replaces it if it’s better.\n",
    "\n",
    "**Recombination vs. Abandonment:**\n",
    "My implementation abandons a fraction `p` (default 0.25) of the worst-performing nests in each generation and replaces them with new random solutions.\n",
    "The paper, however, suggests a more sophisticated approach: instead of simple abandonment, it applies a recombination step similar to Differential Evolution with probability (1 - p_a), introducing more structured variation.\n",
    "\n",
    "**Parameter Choices:**\n",
    "My code uses explicit parameters: `pop_size` (50), `alpha` (1.0), `beta` (1.5), `p` (0.25), and `max_gen` (100).\n",
    "The paper uses similar parameters but refers to them with different symbols $\\mu$, $\\alpha$, $\\gamma$, $p_a$, $\\beta$ and does not always specify default values.\n",
    "\n",
    "**Algorithm Structure:**\n",
    "In my implementation, each solution is processed individually in a loop, and I keep a history of the population for visualization.\n",
    "The paper describes a more batch-oriented process: all solutions are perturbed first, then selection and recombination are applied to the whole population.\n",
    "\n",
    "**Additional Features:**\n",
    "My code includes explicit boundary clipping to ensure solutions stay within the allowed range, and I track the population history for later analysis or animation.\n",
    "The paper does not mention boundary handling or keeping a history of populations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Read the Introduction of “An analysis of why cuckoo search does not bring any novel ideas to optimization.” Identify and outline three criteria proposed by the authors for evaluating the underlying metaphor of the algorithm. Critically reflect on these criteria, do you find them appropriate and sufficient? Can you suggest any additional criteria or alternative perspectives that might enrich the evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Criteria for Evaluating the Metaphor\n",
    "\n",
    "From the Introduction of “An analysis of why cuckoo search does not bring any novel ideas to optimization”:\n",
    "\n",
    "1. **Usefulness**: Does the metaphor introduce concepts that effectively solve optimization problems?\n",
    "2. **Novelty**: Were the metaphor-derived concepts original in stochastic optimization when proposed?\n",
    "3. **Sound Motivation**: Is there a robust justification for using the metaphor?\n",
    "\n",
    "## Reflection\n",
    "\n",
    "- **Appropriateness**: The criteria are relevant but overly narrow. **Usefulness** correctly probes the metaphor’s practical contribution, but its focus on “concepts” ignores whether the algorithm delivers superior results. **Novelty** is essential to avoid redundant rebranding of existing methods, yet it risks dismissing incremental improvements that lack originality but enhance performance. **Sound Motivation** is vague, as it assumes metaphors must mirror natural optimization processes, which may not always be necessary for effective algorithms.\n",
    "  \n",
    "- **Sufficiency**: The criteria are insufficient for a comprehensive evaluation. They prioritize the metaphor’s theoretical role over the algorithm’s real-world impact, implementation rigor, or generalizability. By focusing solely on the metaphor, they sideline critical aspects like computational efficiency or robustness, which are vital for practical optimization algorithms. This narrow lens may unfairly dismiss algorithms that, while metaphorically unoriginal, offer tangible benefits.\n",
    "\n",
    "- **Additional Criteria/Alternatives**:\n",
    "  - **Empirical Superiority**: The criteria should include rigorous benchmarking against state-of-the-art algorithms. A metaphor may lack novelty but inspire an algorithm that outperforms competitors, which the current criteria undervalue.\n",
    "  - **Implementation Consistency**: Evaluate whether the metaphor translates coherently into the algorithm’s mechanics. The paper itself notes discrepancies between the cuckoo metaphor and its implementation, suggesting this as a critical oversight.\n",
    "  - **Scalability and Versatility**: Assess the algorithm’s performance across diverse problem sizes and types. A metaphor-driven algorithm should demonstrate robust applicability, not just theoretical alignment.\n",
    "  - **Interpretability**: Consider whether the metaphor aids in explaining the algorithm to practitioners or researchers. A metaphor that obscures understanding (e.g., inconsistent terminology in CS) can hinder adoption, regardless of its novelty.\n",
    "  \n",
    "- **Critical Perspective**: The authors’ criteria reflect a purist stance, potentially stifling innovation by demanding strict originality and natural alignment. Many successful algorithms (e.g., genetic algorithms) build on existing ideas but refine them effectively. Dismissing metaphor-based algorithms like CS without weighing their practical contributions or potential for adaptation risks academic gatekeeping. A balanced evaluation should integrate theoretical rigor with empirical and practical considerations, acknowledging that metaphors often serve as intuitive scaffolds rather than literal blueprints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Read Section 4 of “An analysis of why cuckoo search does not bring any novel ideas to optimization.” Explain the main criticisms they raise against the Cuckoo Search algorithm. What fundamental issues do they identify, and how do these undermine the algorithm's novelty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Criticisms of Cuckoo Search:\n",
    "\n",
    "**Zero Novelty:** Cuckoo Search is identical to the (μ + λ)-Evolution Strategy from 1981, just with different terminology\n",
    "\n",
    "**False Metaphor:** The cuckoo breeding behavior isn't actually an optimization process - the authors artificially added \"survival of the fittest\" which doesn't exist in real cuckoo behavior\n",
    "\n",
    "**Internal Inconsistency:** The published algorithm description doesn't match the actual implementation code\n",
    "\n",
    "**Fundamental Issue:** The algorithm contributes nothing new to optimization - it's a 30-year-old evolutionary algorithm disguised with bird metaphors, representing the broader problem of \"fake novelty\" in computational intelligence research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Analyze Figures 5 and 8 from [Large-scale Benchmarking of Metaphor-based Optimization Heuristics](https://arxiv.org/pdf/2402.09800). In these figures, Cuckoo Search is denoted as CS. Evaluate its performance relative to the CMA-ES variant (bipop) and Differential Evolution (DE). How does CS compare to these well-established algorithms in terms of optimization performance? Furthermore, critically consider whether performance alone is a sufficient criterion for evaluating optimization algorithms. What other factors should be taken into account?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Comparison:\n",
    "\n",
    "**Figure 5 (Fixed-Budget):** CS ranks top on some functions in dimensionality 10, competitive with DE at lower budgets but outperformed by BIPOP-CMA-ES on harder functions at higher budgets.\n",
    "**Figure 8 (Anytime):** CS shows high AOCC and distinct performance, complementing BIPOP-CMA-ES and DE with strong, unique optimization capabilities.\n",
    "\n",
    "#### Critical Evaluation:\n",
    "Performance alone is insufficient for evaluating optimization algorithms. CS’s strong performance is undermined by its lack of novelty as an ES reformulation. Other factors to consider include algorithmic novelty, implementation reproducibility, parameter tunability, generalizability across problem types, portfolio contribution, computational efficiency, and specialist vs. generalist behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
